---
title: "Uncovering Machine Learning's Potential in Nowcasting GDP"
#author: "SEM Presentation"
# date: "29 June 2023"
format:
  revealjs: 
    theme: slides.scss
    slide-number: true
    transition: fade
    background-transition: fade
code-link: true
code-fold: true
execute:
  echo: true
  freeze: auto
jupyter: python3
---

# Introduction

## Collaborators

We have a team of people that consists of statisticians, econometricians and data scientists / engineers.

-   **Dawie van Lill** üó£Ô∏è
-   Fran√ßois Kamper 
-   Hylton Hollander
-   Sebastian Krantz

::: aside
üìß dvanlill@sun.ac.za
:::

## Research question(s)

There are two parts to our research question. One part relates to performance, the other to ease of use. 

<br>

> Do machine learning (and deep learning) methods contribute to forecasting performance over and above the traditional forecasting models? How easy are these methods to implement?


## Managing expectations

<br>

This is **not** a technical talk on the methods used. 

The talk is more about our results and the way that our experience translates to practitioners.

<br>


:::{.callout-important}
## Please reach out

Contact us after the presentation to discuss model details. We would love to know how we can improve our models! 

:::

## Contribution

ARIMA forecasting benchmark versus DFM, ML and DL

::: columns
::: {.column width="50%" style="text-align: center;"}

**DFM and ML models**

::: goal
1. DFM (M)
2. SVR (M)
3. RF (M)
4. GBM (M)
:::
:::

::: {.column width="50%" style="text-align: center;"}

**MLP-based models**

::: goal
5. MLP (M)
6. N-BEATS (U & M)
7. N-HiTS (M)

::: aside
U = Univariate, M = Multivariate, MLP = Multilayer Perceptron
:::


:::
:::
:::

## Contribution

ARIMA forecasting benchmark versus DFM, ML and DL

::: columns
::: {.column width="50%" style="text-align: center;"}

**RNN-based models**

::: goal
8. RNN (M)
9. RNN-LSTM (M)
10. RNN-GRU (M)
11. TCN (M)
12. DilatedRNN (M)
:::
:::

::: {.column width="50%" style="text-align: center;"}

**Transformer models**

::: goal
13. Temporal Fusion Transformer (U)
14. Autoformer (M)
15. Informer (M)


::: aside
RNN = Recurrent neural network
:::


:::
:::
:::



## Useful libraries

<br>

![](02_figures/ray_tune.png){.absolute top=100 left=50 width="250" height="200"}

![](02_figures/nixtla_new.png){.absolute top=75 right=150 width="350" height="350"}

![](02_figures/Darts-Time-Series-Made-Easy-in-Python-100-694x392.jpg){.absolute bottom=20 right=300 width="500" height="300"}


# Data

## Data

<br> 
 

The **target variable** is the seasonally adjusted annualised quarter-on-quarter growth rate of GDP covering the period from 1959Q2 to 2023Q5. 

<br> 

::: columns
Quarterly and monthly macroeconomic variables are collected using data from the FRED-QD and FRED-MD databases. Suggested transformation of variables applied. 
:::

::: columns

:::


## Data preparation

<br>

Monthly vintage data is available.

<br>

We **block** the monthly data to resolve the mixed frequency problem.

<br>


This means that we create new variables from the values of the 1st, 2nd, and 3rd month of each quarter.


## Dynamic factor model

## Machine learning models

## MLP-based models

<center>
![](02_figures/mlp_model.png){
width=70% }
</center>

## 


## RNN-based models

<center>
![](02_figures/rnn_model.png){
width=70% }
</center>

##

## Transformer models

<center>
![](02_figures/transformer.svg){
height=50% }
</center>

## 


# Results



# Conclusion



