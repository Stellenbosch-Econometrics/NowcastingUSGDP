---
title: "Uncovering Machine Learning's Potential in Nowcasting GDP"
#author: "SEM Presentation"
# date: "29 June 2023"
format:
  revealjs: 
    theme: slides.scss
    slide-number: true
    transition: fade
    background-transition: fade
code-link: true
code-fold: true
execute:
  echo: true
  freeze: auto
jupyter: python3
bibliography: biblio.bib
---

# Introduction

## Collaborators

We have a team of people that consists of statisticians, econometricians and data scientists.

-   **Dawie van Lill** üó£Ô∏è
-   Fran√ßois Kamper
-   Sebastian Krantz

::: aside
üìß dvanlill\@sun.ac.za
:::

## Research question(s)

There are two parts to our research question. One part relates to performance, the other to ease of use.

<br>

> Do machine learning (and deep learning) methods contribute to forecasting performance over and above the traditional forecasting models? How easy are these methods to implement?

## Managing expectations

<br>

This is **not** a technical talk on the methods used.

The talk is more about our results and the way that our experience translates to practitioners.

<br>

::: callout-important
## Please reach out

Contact us after the presentation to discuss model details. We would love to know how we can improve our models!
:::

## Contribution

Naive forecasting benchmark versus DFM, ML and DL

::: columns
::: {.column width="50%" style="text-align: center;"}
**DFM and ML models**

::: goal
1.  DFM (M)
2.  SVR (M)
3.  RF (M) *
4.  GBM (M) *
:::
:::

::: {.column width="50%" style="text-align: center;"}
**MLP-based models**

::: goal
5.  MLP (M)
6.  N-BEATS (U & M)
7.  N-HiTS (M)

::: aside
U = Univariate, M = Multivariate, MLP = Multilayer Perceptron
:::
:::
:::
:::

## Contribution

Naive forecasting benchmark versus DFM, ML and DL

::: columns
::: {.column width="50%" style="text-align: center;"}
**RNN-based models**

::: goal
8.  RNN (M)
9.  RNN-LSTM (M)
10. RNN-GRU (M)
11. TCN (M)
12. DilatedRNN (M)
:::
:::

::: {.column width="50%" style="text-align: center;"}
**Transformer models**

::: goal
13. Temporal Fusion Transformer (U)
14. Informer (M)
15. Autoformer (M)

::: aside
RNN = Recurrent neural network
:::
:::
:::
:::

## Useful libraries

<br>

![](02_figures/ray_tune.png){.absolute top="100" left="50" width="250" height="200"}

![](02_figures/nixtla_new.png){.absolute top="75" right="150" width="350" height="350"}

![](02_figures/Darts-Time-Series-Made-Easy-in-Python-100-694x392.jpg){.absolute bottom="20" right="300" width="500" height="300"}

# Data

## Data

<br>

The **target variable** is the seasonally adjusted annualised quarter-on-quarter growth rate of GDP covering the period from 1959Q2 to 2023Q2.

<br>

Quarterly and monthly macroeconomic variables are collected using data from the FRED-QD and FRED-MD databases. Suggested transformation of variables applied.


## Data preparation

<br>

Monthly vintage data is available. GDP is available at quarterly frequency. This creates a mixed frequency problem. 

<br>

We **block** the monthly data to resolve this problem. 

 - This means that we create new variables from the values of the 1st, 2nd, and 3rd month of each quarter.

# Dynamic factor models

## Dynamic factor models {.smaller}

<br>

We estimate a Mixed Frequency DFM following @banbura2014maximum, using a global specification with 9 factors related through a VAR(4), or a blocked structure following @bok2018macroeconomic with 13 factors in 9 blocks:

<br>

::: goal
global (2), output and income (1), labor market (1), consumption, orders, and inventories (2), housing (1), money and credit (2), interest and exchange rates (2), prices (1), and stock market (1).
:::

## Dynamic factor models {.smaller}

<br> 

We also estimate bridge-equation models with monthly DFMs along two methods

1. Aggregating monthly factors + linear model to nowcast GDP
2. Distributing monthly factors into multiple quarterly variables and using LASSO for nowcasting. 
 
<br>

These bridge models also allow either a **global** or *blocked* factor structure.

<br> 
The purpose of having both mixed-frequency and bridge equation models is to gauge the potential gains from mixed-frequency in DFM estimation.

##

# Machine learning models

## Support vector regression

Different kernels for SVR model...

## 

## MLP-based models

<center>![](02_figures/mlp_model.png){width="70%"}</center>

## MLP-based models

We consider three types of MLP-based models

1. MLP
2. N-BEATS and N-BEATSx
3. N-HiTS

<br>

N-BEATS and N-HiTS employ learnable architecture that directly learns the historical data's backward and forward-looking components


## 

## RNN-based models

<center>![](02_figures/rnn_model.png){width="70%"}</center>

## RNN-based models {.smaller}

We consider five types of RNN-based models

1. RNN
2. RNN-LSTM
3. RNN-GRU
4. TCN
5. Dilated RNN

<br>

LSTM and GRU differ from traditional RNNs in that LSTM and GRU incorporate gating mechanisms to mitigate the vanishing gradient problem, allowing them to capture long-term dependencies. 

## RNN-based models


Dilated RNN uses dilation in time (skipped steps) to capture longer sequences without increasing the number of parameters.

<br>

TCNs use dilated causal convolutions to process sequences, allowing them to efficiently handle long-term dependencies and offering more parallelism.

## 

## Transformer models

<center>![](02_figures/transformer.svg){height="50%"}</center>

## Transformer models

We consider three types of transformer based models

1. Temporal fusion transformer
2. Informer
3. Autoformer

Transformer-based models differ from traditional Recurrent Neural Networks (RNNs) by employing self-attention mechanisms for sequence processing, which allows them to capture dependencies regardless of their position in the sequence, offering improved parallelization capabilities and mitigating issues with long-term dependencies, as opposed to RNNs which process sequences step-by-step and can struggle with long-term dependencies due to the vanishing gradient problem.


##


# Results

#  {.smaller}

<!-- html table generated in R 4.3.0 by xtable 1.8-4 package -->

<!-- Sun Jun 18 23:11:04 2023 -->

+-------------------+-------+------+------+--------+------+------------+------------+------------+
|                   | Bias  | RMSE | MAE  | MAPE   | U2   | Bias Prop. | Var. Prop. | Cov. Prop. |
+===================+=======+======+======+========+======+============+============+============+
| AutoGRU           | 0.43  | 0.85 | 0.62 | 100.56 | 0.52 | 0.26       | 0.07       | 0.68       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoRNN           | 0.40  | 0.88 | 0.65 | 108.31 | 0.54 | 0.21       | 0.01       | 0.78       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoDilatedRNN    | 0.46  | 0.94 | 0.68 | 105.64 | 0.55 | 0.24       | 0.06       | 0.70       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoLSTM          | 0.42  | 0.99 | 0.65 | 110.16 | 0.60 | 0.17       | 0.28       | 0.55       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| DFM_global        | -0.14 | 1.02 | 0.71 | 115.06 | 0.72 | 0.02       | 0.02       | 0.96       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| DFM_blocked       | -0.15 | 1.34 | 0.79 | 117.14 | 0.58 | 0.01       | 0.02       | 0.97       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| DFM_lasso_global  | -0.16 | 1.44 | 0.80 | 92.40  | 0.51 | 0.01       | 0.31       | 0.68       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| DFM_lasso_blocked | -0.18 | 1.61 | 0.81 | 109.57 | 0.55 | 0.01       | 0.08       | 0.91       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| DFM_lm_global     | -0.45 | 1.66 | 1.11 | 132.48 | 0.77 | 0.07       | 0.08       | 0.85       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| DFM_lm_blocked    | -0.31 | 1.68 | 0.87 | 98.37  | 0.63 | 0.03       | 0.02       | 0.95       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoTCN           | 0.53  | 1.72 | 0.88 | 109.74 | 0.75 | 0.10       | 0.59       | 0.31       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoMLP_alt       | 0.18  | 2.82 | 1.40 | 117.86 | 0.87 | 0.00       | 0.69       | 0.31       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoNBEATS        | 0.12  | 3.05 | 1.69 | 158.31 | 0.93 | 0.00       | 0.29       | 0.71       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoInformer      | 0.38  | 3.06 | 1.54 | 151.53 | 0.96 | 0.02       | 0.37       | 0.61       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoNHITS         | 0.21  | 3.09 | 1.84 | 137.96 | 1.06 | 0.00       | 0.09       | 0.91       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoMLP           | 0.07  | 3.46 | 1.86 | 133.97 | 0.93 | 0.00       | 0.07       | 0.93       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoAutoformer    | 0.41  | 3.52 | 1.87 | 169.65 | 1.23 | 0.01       | 0.07       | 0.92       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoNHITS_alt     | 0.01  | 3.83 | 2.19 | 186.29 | 1.05 | 0.00       | 0.01       | 0.99       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| AutoNBEATSx       | -0.03 | 3.85 | 2.19 | 172.27 | 1.04 | 0.00       | 0.01       | 0.99       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
| Naive             | 0.00  | 4.62 | 2.24 | 152.15 | 1.00 | 0.00       | 0.00       | 1.00       |
+-------------------+-------+------+------+--------+------+------------+------------+------------+
|                   |       |      |      |        |      |            |            |            |
+-------------------+-------+------+------+--------+------+------------+------------+------------+

# Conclusion

# References